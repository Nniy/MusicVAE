{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jKJvXJNBa_a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "#DATA IMPORTING LIBRARIES\n",
    "# Add the src folder to the path\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "from data.dataloader import MidiDataset\n",
    "from data.bar_transform import BarTransform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "#half of this is not yet needed but maybe it will be to visualize the latent space\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, Audio, display, clear_output\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))\n",
    "\n",
    "from midi_builder import MidiBuilder\n",
    "builder = MidiBuilder()\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "NOTESPERBAR=16 #total notes in one bar\n",
    "\n",
    "totalbars=16 #total bars as input \n",
    "NUM_PITCHES=60 # all possible notes to play\n",
    "\n",
    "\n",
    "TOTAL_NOTES=NOTESPERBAR*totalbars\n",
    "\n",
    "num_features=NUM_PITCHES #size of input feature vector\n",
    "\n",
    "batch_size = 32 #actual batchsize\n",
    "\n",
    "TEACHER_FORCING=True #not used but it will be needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Ramiro\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20848, Test size: 5211\n"
     ]
    }
   ],
   "source": [
    "transform = BarTransform(bars=totalbars, note_count=NUM_PITCHES)#configures number of input bars\n",
    "\n",
    "midi_dataset = MidiDataset(csv_file='./concat.csv', transform = transform) #imports dataset\n",
    "\n",
    "midi_dataset.get_mem_usage()\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "test_split = .2\n",
    "shuffle = True\n",
    "\n",
    "if random_seed is not None:\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    \n",
    "dataset_size = len(midi_dataset)           #number of musics on dataset\n",
    "test_size = int(test_split * dataset_size) #test size length\n",
    "train_size = dataset_size - test_size      #train data length\n",
    "\n",
    "train_dataset, test_dataset = random_split(midi_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=4)#, sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=4)#, sampler=test_sampler)\n",
    "\n",
    "print(\"Train size: {}, Test size: {}\".format(train_size, test_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1jGsBaPFNmy"
   },
   "source": [
    "MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "2ASED3VFFKoU",
    "outputId": "540ba87b-7ebd-4565-b6c0-0a3f8ad3ebb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): LSTM(60, 512, batch_first=True, bidirectional=True)\n",
      "  (encoderOut): Linear(in_features=1024, out_features=40, bias=True)\n",
      "  (linear_z): Linear(in_features=20, out_features=32, bias=True)\n",
      "  (dropout): Dropout(p=0.05)\n",
      "  (conductor): LSTM(32, 32, batch_first=True)\n",
      "  (decoder): LSTM(92, 32, batch_first=True)\n",
      "  (linear): Linear(in_features=32, out_features=60, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define size variables\n",
    "input_size = NUM_PITCHES\n",
    "\n",
    "enc_hidden_size=512 #hidden size of encoder\n",
    "conductor_hidden_size=60 #hidden size of decoder\n",
    "\n",
    "decoders_hidden_size=256 #hidden size of decoder\n",
    "decoders_initial_size=32 #decoder input size\n",
    "\n",
    "n_layers_conductor=2 #not being used rn cuz number of layers is incorrect\n",
    "n_layers_decoder=3 #not being used rn cuz number of layers is incorrect\n",
    "\n",
    "latent_features=20 #latent space dimension\n",
    "\n",
    "sequence_length = 16 #notes per decoder\n",
    "\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features,teacher_forcing):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.latent_features = latent_features\n",
    "               \n",
    "        #data goes into bidirectional encoder\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "                batch_first = True,\n",
    "                input_size = input_size,\n",
    "                hidden_size = enc_hidden_size,\n",
    "                num_layers = 1,\n",
    "                bidirectional = True)\n",
    "        \n",
    "        self.conductor = torch.nn.LSTM(input_size=latent_features, hidden_size=conductor_hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        \n",
    "        self.hidden2mean = nn.Linear(enc_hidden_size * 2, latent_features)\n",
    "        self.hidden2logv = nn.Linear(enc_hidden_size * 2, latent_features)\n",
    "\n",
    "        \n",
    "    #used to initialize the hidden layer of the encoder to zero before every batch\n",
    "    def init_hidden(self, batch_size):\n",
    "        #must be 2 x batch x hidden_size because its a bi-directional LSTM\n",
    "        init = torch.zeros(2, batch_size, enc_hidden_size, device=device)\n",
    "        c0 = torch.zeros(2, batch_size, enc_hidden_size, device=device)\n",
    "    \n",
    "        #2 because has 2 layers\n",
    "        #n_layers_conductor\n",
    "        init_conductor = torch.zeros(1, batch_size, conductor_hidden_size, device=device)\n",
    "        c_condunctor = torch.zeros(1, batch_size, conductor_hidden_size, device=device)\n",
    "    \n",
    "        #2 because has 2 layers\n",
    "        #n_layers_decoder\n",
    "        #init_decoders = torch.zeros(1, batch_size, decoders_hidden_size, device=device)\n",
    "        #c_decoders= torch.zeros(1, batch_size, decoders_hidden_size, device=device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return init,c0,init_conductor,c_condunctor\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "    \n",
    "        outputs = {}\n",
    "                \n",
    "        #creates hidden layer values\n",
    "        h0,c0,hconductor,cconductor = self.init_hidden(batch_size)\n",
    "           \n",
    "        #print(\"in\",x.shape)\n",
    "        \n",
    "        #resets encoder at the beginning of every batch and gives it x\n",
    "        x, hidden = self.encoder(x, ( h0,c0))\n",
    "        \n",
    "        mu = self.hidden2mean(x)\n",
    "        log_var = self.hidden2logv(x)\n",
    "\n",
    "        \n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, 1, latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        #setting sigma\n",
    "        sigma = torch.exp(log_var * 0.5)\n",
    "              \n",
    "        #generate z - latent space\n",
    "        z = mu + epsilon * sigma\n",
    "        \n",
    "        #print(\"z\",z.shape)\n",
    "\n",
    "        conductor_hidden = (hconductor,cconductor)\n",
    "        \n",
    "        embedding, conductor_hidden = self.conductor(z, conductor_hidden)    \n",
    "        \n",
    "        \n",
    "        outputs[\"x_hat\"] = torch.softmax(embedding, dim=2);\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "net = VariationalAutoencoder(latent_features,TEACHER_FORCING)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUoxLXafiv1n"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEjjddpwdFZH"
   },
   "outputs": [],
   "source": [
    "#directly taken from notebook, probably some adaptation might be needed\n",
    "\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "\n",
    "\n",
    "def ELBO_loss(y, t, mu, log_var, weight):\n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "    likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "    likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    sigma = torch.exp(log_var*2)\n",
    "    n_mu = torch.Tensor([0])\n",
    "    n_sigma = torch.Tensor([1])\n",
    "    if cuda:\n",
    "        n_mu = n_mu.cuda()\n",
    "        n_sigma = n_sigma.cuda()\n",
    "\n",
    "    p = Normal(n_mu, n_sigma)\n",
    "    q = Normal(mu, sigma)\n",
    "\n",
    "    #The method signature is P and Q, but might need to be reversed to calculate divergence of Q with respect to P\n",
    "    kl_div = kl_divergence(q, p)\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    #kl = -weight * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=(1,2))\n",
    "    \n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood)# - (weight*torch.mean(kl_div)) # add a weight to the kl using warmup\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl_div.mean() # mean instead of sum\n",
    "\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = ELBO_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb4f2WjmGAfx"
   },
   "source": [
    "Testing if forward pass works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1007
    },
    "colab_type": "code",
    "id": "mlCBcLJ-GCeN",
    "outputId": "2ea353bc-0884-4a78-8e89-44cf52587026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 60)\n",
      "torch.Size([2, 256, 60])\n",
      "torch.Size([2, 256, 60])\n",
      "torch.Size([2, 256, 32])\n",
      "tensor(1304.1294, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(6.1489, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "#setting dummy data\n",
    "#Generating dummy data\n",
    "a= np.random.randint(NUM_PITCHES, size=TOTAL_NOTES)\n",
    "data = np.zeros((TOTAL_NOTES, NUM_PITCHES))\n",
    "data[np.arange(TOTAL_NOTES), a] = 1 #generating dummy data\n",
    "\n",
    "a= np.random.randint(NUM_PITCHES, size=TOTAL_NOTES)\n",
    "data1 = np.zeros((TOTAL_NOTES, NUM_PITCHES))\n",
    "data1[np.arange(TOTAL_NOTES), a] = 1 #generating dummy data\n",
    "d=np.zeros((2,TOTAL_NOTES, NUM_PITCHES))\n",
    "d[0]=data\n",
    "d[1]=data1\n",
    "\n",
    "print(d.shape)\n",
    "\n",
    "#adding 1 dimension, 1x32x4\n",
    "x = d#data[np.newaxis, :, :]\n",
    "\n",
    "\n",
    "\n",
    "#setting input ans tensor variable\n",
    "x = Variable(torch.Tensor(x))\n",
    "\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "    \n",
    "    \n",
    "\n",
    "#running forward pass\n",
    "outputs = net(x)\n",
    "\n",
    "\n",
    "#AFTER THIS NOTHING IS DONE YET ------\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "loss, kl = loss_function(x_hat, x, mu, log_var,1)\n",
    "\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "print(loss)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0f069eaf3592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_var'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Ramiro\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a60326df4f4a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m#setting sigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "tmp_img = \"tmp_vae_out.png\"\n",
    "\n",
    "# 3 = ~12 minutes\n",
    "num_epochs = 100\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "train_kl, valid_kl = [], []\n",
    "\n",
    "# Warmup weights\n",
    "weight = 1 / (num_epochs - 1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Training epoch {}\".format(0))\n",
    "#epochs loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    batch_loss, batch_kl = [], []\n",
    "    net.train()\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        #if i_batch == 10:\n",
    "        #    break\n",
    "        x = sample_batched['piano_rolls']\n",
    "\n",
    "        x = x.type('torch.FloatTensor')\n",
    "        \n",
    "        #if i_batch%10==0:\n",
    "        #    print(\"batch:\",i_batch)\n",
    "\n",
    "        x = Variable(x)\n",
    "\n",
    "        # This is an alternative way of putting\n",
    "        # a tensor on the GPU\n",
    "        x = x.to(device)\n",
    "\n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var, weight)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss.append(elbo.item())\n",
    "        batch_kl.append(kl.item())\n",
    "\n",
    "    train_loss.append(np.mean(batch_loss))\n",
    "    train_kl.append(np.mean(batch_kl))\n",
    "\n",
    "    # Evaluate, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "\n",
    "        # Just load a single batch from the test loader\n",
    "        x = next(iter(test_loader))\n",
    "        x = Variable(x['piano_rolls'].type('torch.FloatTensor'))\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        z = outputs[\"z\"]\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var, 1.0)\n",
    "\n",
    "        # We save the latent variable and reconstruction for later use\n",
    "        # we will need them on the CPU to plot\n",
    "        x = x.to(\"cpu\")\n",
    "        x_hat = x_hat.to(\"cpu\")\n",
    "        z = z.detach().to(\"cpu\").numpy()\n",
    "\n",
    "        valid_loss.append(elbo.item())\n",
    "        valid_kl.append(kl.item())\n",
    "\n",
    "    if epoch == 0:\n",
    "        continue\n",
    "            \n",
    "    # -- Plotting --\n",
    "    f, axarr = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    \n",
    "    \n",
    "    # Loss\n",
    "    ax = axarr[0]\n",
    "    ax.set_title(\"ELBO\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Error')\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_loss, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_loss, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    \n",
    "    \n",
    "    # KL / reconstruction\n",
    "    ax = axarr[1]\n",
    "    \n",
    "    ax.set_title(\"Kullback-Leibler Divergence\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('KL divergence')\n",
    "\n",
    "\n",
    "    ax.plot(np.arange(epoch+1), train_kl, color=\"black\")\n",
    "    ax.plot(np.arange(epoch+1), valid_kl, color=\"gray\", linestyle=\"--\")\n",
    "    ax.legend(['Training', 'Validation'])\n",
    "    \n",
    "    print(\"Epoch: {}, {} seconds elapsed\".format(epoch, time.time() - start))\n",
    "    \n",
    "    plt.savefig(tmp_img)\n",
    "    plt.close(f)\n",
    "    display(Image(filename=tmp_img))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "\n",
    "    os.remove(tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4467e+00, 1.9657e+01, 3.9946e+00, 6.1268e+00, 2.5426e+01, 2.2764e+02,\n",
      "         7.2790e+00, 1.8640e+01, 4.2117e+00, 1.8373e+33, 2.4963e+01, 7.0885e-01,\n",
      "         2.9731e+01, 1.8100e+01, 2.1768e+01, 5.7642e+01, 7.9992e-02, 1.0539e+03,\n",
      "         2.7513e+01, 1.1110e+00],\n",
      "        [3.3021e+00, 1.9667e+01, 4.0010e+00, 6.1294e+00, 2.5433e+01, 2.2788e+02,\n",
      "         7.2818e+00, 1.8650e+01, 4.2082e+00, 1.8575e+33, 2.4981e+01, 7.0948e-01,\n",
      "         2.9751e+01, 1.8110e+01, 2.1779e+01, 5.7693e+01, 7.9818e-02, 1.0494e+03,\n",
      "         2.7522e+01, 1.1136e+00],\n",
      "        [3.3978e+00, 1.9690e+01, 4.0051e+00, 6.1458e+00, 2.5480e+01, 2.2861e+02,\n",
      "         7.2954e+00, 1.8679e+01, 4.2184e+00, 1.8989e+33, 2.5007e+01, 7.0560e-01,\n",
      "         2.9792e+01, 1.8140e+01, 2.1809e+01, 5.7849e+01, 7.9371e-02, 1.0488e+03,\n",
      "         2.7563e+01, 1.1100e+00],\n",
      "        [3.4466e+00, 1.9658e+01, 3.9945e+00, 6.1252e+00, 2.5424e+01, 2.2745e+02,\n",
      "         7.2768e+00, 1.8639e+01, 4.2070e+00, 1.8156e+33, 2.4963e+01, 7.0838e-01,\n",
      "         2.9730e+01, 1.8100e+01, 2.1764e+01, 5.7621e+01, 7.9917e-02, 1.0517e+03,\n",
      "         2.7504e+01, 1.1119e+00],\n",
      "        [3.2306e+00, 1.9686e+01, 3.9997e+00, 6.1334e+00, 2.5459e+01, 2.2823e+02,\n",
      "         7.2907e+00, 1.8670e+01, 4.2184e+00, 1.8526e+33, 2.4997e+01, 7.0877e-01,\n",
      "         2.9772e+01, 1.8126e+01, 2.1797e+01, 5.7718e+01, 8.0100e-02, 1.0551e+03,\n",
      "         2.7554e+01, 1.1111e+00],\n",
      "        [3.4447e+00, 1.9635e+01, 3.9891e+00, 6.1156e+00, 2.5391e+01, 2.2696e+02,\n",
      "         7.2669e+00, 1.8616e+01, 4.2058e+00, 1.7943e+33, 2.4930e+01, 7.0993e-01,\n",
      "         2.9693e+01, 1.8073e+01, 2.1737e+01, 5.7463e+01, 8.0355e-02, 1.0536e+03,\n",
      "         2.7475e+01, 1.1117e+00],\n",
      "        [3.4195e+00, 1.9641e+01, 3.9916e+00, 6.1193e+00, 2.5401e+01, 2.2722e+02,\n",
      "         7.2709e+00, 1.8624e+01, 4.2082e+00, 1.8156e+33, 2.4939e+01, 7.0946e-01,\n",
      "         2.9707e+01, 1.8081e+01, 2.1747e+01, 5.7529e+01, 8.0242e-02, 1.0518e+03,\n",
      "         2.7487e+01, 1.1118e+00],\n",
      "        [3.4447e+00, 1.9635e+01, 3.9891e+00, 6.1156e+00, 2.5391e+01, 2.2696e+02,\n",
      "         7.2669e+00, 1.8616e+01, 4.2058e+00, 1.7943e+33, 2.4930e+01, 7.0993e-01,\n",
      "         2.9693e+01, 1.8073e+01, 2.1737e+01, 5.7463e+01, 8.0355e-02, 1.0536e+03,\n",
      "         2.7475e+01, 1.1117e+00],\n",
      "        [3.3686e+00, 1.9678e+01, 3.9962e+00, 6.1274e+00, 2.5434e+01, 2.2800e+02,\n",
      "         7.2855e+00, 1.8660e+01, 4.2172e+00, 1.8292e+33, 2.4981e+01, 7.1055e-01,\n",
      "         2.9756e+01, 1.8110e+01, 2.1773e+01, 5.7673e+01, 8.0602e-02, 1.0607e+03,\n",
      "         2.7532e+01, 1.1107e+00],\n",
      "        [3.3692e+00, 1.9667e+01, 3.9941e+00, 6.1248e+00, 2.5427e+01, 2.2770e+02,\n",
      "         7.2817e+00, 1.8647e+01, 4.2152e+00, 1.8409e+33, 2.4970e+01, 7.1040e-01,\n",
      "         2.9742e+01, 1.8102e+01, 2.1770e+01, 5.7666e+01, 8.0482e-02, 1.0539e+03,\n",
      "         2.7520e+01, 1.1117e+00],\n",
      "        [3.4449e+00, 1.9636e+01, 3.9893e+00, 6.1160e+00, 2.5392e+01, 2.2694e+02,\n",
      "         7.2673e+00, 1.8617e+01, 4.2061e+00, 1.7944e+33, 2.4932e+01, 7.0989e-01,\n",
      "         2.9695e+01, 1.8074e+01, 2.1738e+01, 5.7468e+01, 8.0409e-02, 1.0536e+03,\n",
      "         2.7477e+01, 1.1118e+00],\n",
      "        [3.4068e+00, 1.9635e+01, 3.9901e+00, 6.1163e+00, 2.5396e+01, 2.2739e+02,\n",
      "         7.2677e+00, 1.8618e+01, 4.2062e+00, 1.7961e+33, 2.4933e+01, 7.0985e-01,\n",
      "         2.9697e+01, 1.8076e+01, 2.1741e+01, 5.7449e+01, 8.0372e-02, 1.0518e+03,\n",
      "         2.7478e+01, 1.1121e+00],\n",
      "        [3.4410e+00, 1.9641e+01, 3.9916e+00, 6.1176e+00, 2.5390e+01, 2.2714e+02,\n",
      "         7.2689e+00, 1.8621e+01, 4.2079e+00, 1.7955e+33, 2.4931e+01, 7.1014e-01,\n",
      "         2.9700e+01, 1.8075e+01, 2.1735e+01, 5.7275e+01, 8.0614e-02, 1.0575e+03,\n",
      "         2.7482e+01, 1.1116e+00],\n",
      "        [3.4382e+00, 1.9647e+01, 3.9906e+00, 6.1190e+00, 2.5400e+01, 2.2760e+02,\n",
      "         7.2743e+00, 1.8630e+01, 4.2105e+00, 1.8138e+33, 2.4944e+01, 7.0974e-01,\n",
      "         2.9710e+01, 1.8084e+01, 2.1747e+01, 5.7572e+01, 8.0674e-02, 1.0568e+03,\n",
      "         2.7491e+01, 1.1112e+00],\n",
      "        [3.3462e+00, 1.9656e+01, 3.9939e+00, 6.1255e+00, 2.5434e+01, 2.2848e+02,\n",
      "         7.2793e+00, 1.8647e+01, 4.2104e+00, 1.8275e+33, 2.4963e+01, 7.0871e-01,\n",
      "         2.9733e+01, 1.8102e+01, 2.1771e+01, 5.7475e+01, 7.9992e-02, 1.0468e+03,\n",
      "         2.7512e+01, 1.1121e+00],\n",
      "        [3.4457e+00, 1.9647e+01, 3.9923e+00, 6.1223e+00, 2.5412e+01, 2.2733e+02,\n",
      "         7.2745e+00, 1.8631e+01, 4.2099e+00, 1.8252e+33, 2.4950e+01, 7.0906e-01,\n",
      "         2.9718e+01, 1.8090e+01, 2.1756e+01, 5.7587e+01, 8.0272e-02, 1.0518e+03,\n",
      "         2.7500e+01, 1.1115e+00],\n",
      "        [3.4447e+00, 1.9635e+01, 3.9891e+00, 6.1156e+00, 2.5391e+01, 2.2696e+02,\n",
      "         7.2669e+00, 1.8616e+01, 4.2058e+00, 1.7943e+33, 2.4930e+01, 7.0993e-01,\n",
      "         2.9693e+01, 1.8073e+01, 2.1737e+01, 5.7463e+01, 8.0355e-02, 1.0536e+03,\n",
      "         2.7475e+01, 1.1117e+00],\n",
      "        [3.2787e+00, 1.9694e+01, 4.0002e+00, 6.1348e+00, 2.5467e+01, 2.2822e+02,\n",
      "         7.2943e+00, 1.8678e+01, 4.2220e+00, 1.8807e+33, 2.5009e+01, 7.0913e-01,\n",
      "         2.9785e+01, 1.8132e+01, 2.1805e+01, 5.7869e+01, 8.0425e-02, 1.0586e+03,\n",
      "         2.7565e+01, 1.1113e+00],\n",
      "        [3.3888e+00, 1.9645e+01, 3.9902e+00, 6.1169e+00, 2.5407e+01, 2.2777e+02,\n",
      "         7.2744e+00, 1.8629e+01, 4.2077e+00, 1.7977e+33, 2.4949e+01, 7.0949e-01,\n",
      "         2.9707e+01, 1.8087e+01, 2.1749e+01, 5.7412e+01, 8.0390e-02, 1.0530e+03,\n",
      "         2.7483e+01, 1.1117e+00],\n",
      "        [3.4455e+00, 1.9654e+01, 3.9942e+00, 6.1240e+00, 2.5419e+01, 2.2738e+02,\n",
      "         7.2772e+00, 1.8638e+01, 4.2104e+00, 1.8046e+33, 2.4958e+01, 7.0873e-01,\n",
      "         2.9723e+01, 1.8097e+01, 2.1761e+01, 5.7572e+01, 8.0187e-02, 1.0572e+03,\n",
      "         2.7507e+01, 1.1106e+00],\n",
      "        [3.5219e+00, 1.9631e+01, 3.9891e+00, 6.1161e+00, 2.5388e+01, 2.2703e+02,\n",
      "         7.2672e+00, 1.8613e+01, 4.2051e+00, 1.8032e+33, 2.4928e+01, 7.0987e-01,\n",
      "         2.9691e+01, 1.8072e+01, 2.1735e+01, 5.7468e+01, 8.0495e-02, 1.0529e+03,\n",
      "         2.7471e+01, 1.1115e+00],\n",
      "        [3.3792e+00, 1.9655e+01, 3.9937e+00, 6.1242e+00, 2.5419e+01, 2.2737e+02,\n",
      "         7.2764e+00, 1.8638e+01, 4.2109e+00, 1.8175e+33, 2.4956e+01, 7.0907e-01,\n",
      "         2.9725e+01, 1.8094e+01, 2.1761e+01, 5.7554e+01, 8.0068e-02, 1.0524e+03,\n",
      "         2.7507e+01, 1.1113e+00],\n",
      "        [3.3193e+00, 1.9679e+01, 4.0035e+00, 6.1376e+00, 2.5457e+01, 2.2814e+02,\n",
      "         7.2891e+00, 1.8667e+01, 4.2176e+00, 1.8859e+33, 2.4986e+01, 7.0706e-01,\n",
      "         2.9773e+01, 1.8121e+01, 2.1794e+01, 5.7785e+01, 7.9652e-02, 1.0468e+03,\n",
      "         2.7543e+01, 1.1110e+00],\n",
      "        [3.3023e+00, 1.9670e+01, 3.9931e+00, 6.1261e+00, 2.5432e+01, 2.2781e+02,\n",
      "         7.2841e+00, 1.8652e+01, 4.2191e+00, 1.8592e+33, 2.4974e+01, 7.1024e-01,\n",
      "         2.9748e+01, 1.8106e+01, 2.1780e+01, 5.7669e+01, 8.0683e-02, 1.0505e+03,\n",
      "         2.7533e+01, 1.1120e+00],\n",
      "        [3.4432e+00, 1.9631e+01, 3.9877e+00, 6.1128e+00, 2.5379e+01, 2.2709e+02,\n",
      "         7.2651e+00, 1.8612e+01, 4.2055e+00, 1.7839e+33, 2.4923e+01, 7.1018e-01,\n",
      "         2.9684e+01, 1.8067e+01, 2.1726e+01, 5.7422e+01, 8.0676e-02, 1.0561e+03,\n",
      "         2.7466e+01, 1.1118e+00],\n",
      "        [3.4522e+00, 1.9699e+01, 4.0043e+00, 6.1492e+00, 2.5486e+01, 2.2846e+02,\n",
      "         7.3066e+00, 1.8688e+01, 4.2263e+00, 1.9689e+33, 2.5031e+01, 7.0788e-01,\n",
      "         2.9810e+01, 1.8152e+01, 2.1827e+01, 5.8035e+01, 8.0009e-02, 1.0548e+03,\n",
      "         2.7584e+01, 1.1105e+00],\n",
      "        [3.3281e+00, 1.9676e+01, 4.0027e+00, 6.1377e+00, 2.5455e+01, 2.2827e+02,\n",
      "         7.2883e+00, 1.8662e+01, 4.2132e+00, 1.8708e+33, 2.4994e+01, 7.0788e-01,\n",
      "         2.9772e+01, 1.8123e+01, 2.1791e+01, 5.7793e+01, 7.9895e-02, 1.0488e+03,\n",
      "         2.7543e+01, 1.1122e+00],\n",
      "        [3.4464e+00, 1.9653e+01, 3.9932e+00, 6.1239e+00, 2.5416e+01, 2.2729e+02,\n",
      "         7.2767e+00, 1.8635e+01, 4.2105e+00, 1.8258e+33, 2.4957e+01, 7.0961e-01,\n",
      "         2.9723e+01, 1.8094e+01, 2.1761e+01, 5.7592e+01, 8.0215e-02, 1.0534e+03,\n",
      "         2.7504e+01, 1.1115e+00],\n",
      "        [3.4471e+00, 1.9654e+01, 3.9955e+00, 6.1286e+00, 2.5424e+01, 2.2724e+02,\n",
      "         7.2814e+00, 1.8638e+01, 4.2104e+00, 1.8608e+33, 2.4964e+01, 7.0840e-01,\n",
      "         2.9736e+01, 1.8102e+01, 2.1771e+01, 5.7720e+01, 7.9927e-02, 1.0490e+03,\n",
      "         2.7515e+01, 1.1109e+00],\n",
      "        [3.4044e+00, 1.9650e+01, 3.9913e+00, 6.1188e+00, 2.5399e+01, 2.2774e+02,\n",
      "         7.2750e+00, 1.8632e+01, 4.2150e+00, 1.8280e+33, 2.4944e+01, 7.1096e-01,\n",
      "         2.9717e+01, 1.8082e+01, 2.1750e+01, 5.7594e+01, 8.0984e-02, 1.0606e+03,\n",
      "         2.7502e+01, 1.1117e+00],\n",
      "        [3.4443e+00, 1.9637e+01, 3.9892e+00, 6.1151e+00, 2.5391e+01, 2.2698e+02,\n",
      "         7.2680e+00, 1.8619e+01, 4.2064e+00, 1.7942e+33, 2.4933e+01, 7.0975e-01,\n",
      "         2.9695e+01, 1.8075e+01, 2.1735e+01, 5.7497e+01, 8.0574e-02, 1.0560e+03,\n",
      "         2.7476e+01, 1.1116e+00],\n",
      "        [3.4440e+00, 1.9631e+01, 3.9887e+00, 6.1145e+00, 2.5384e+01, 2.2698e+02,\n",
      "         7.2658e+00, 1.8613e+01, 4.2053e+00, 1.7920e+33, 2.4925e+01, 7.0990e-01,\n",
      "         2.9690e+01, 1.8070e+01, 2.1733e+01, 5.7429e+01, 8.0602e-02, 1.0544e+03,\n",
      "         2.7472e+01, 1.1115e+00]], device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "    sigma = torch.exp(log_var*2)\n",
    "    n_mu = torch.Tensor([0])\n",
    "    n_sigma = torch.Tensor([1])\n",
    "    if cuda:\n",
    "        n_mu = n_mu.cuda()\n",
    "        n_sigma = n_sigma.cuda()\n",
    "\n",
    "    p = Normal(n_mu, n_sigma)\n",
    "    q = Normal(mu, sigma)\n",
    "\n",
    "    #The method signature is P and Q, but might need to be reversed to calculate divergence of Q with respect to P\n",
    "    kl_div = kl_divergence(q, p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(torch.mean(kl_div,dim=1)) # add a weight to the kl using warmup\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    " #   return -ELBO, kl_div.mean() # mean instead of sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('midi'):\n",
    "    os.makedirs('midi')\n",
    "\n",
    "x_hat_np = x_hat.detach().numpy()\n",
    "x_hat_np.shape\n",
    "for i, seq in enumerate(x_hat_np):\n",
    "    row_maxes = seq.max(axis=1).reshape(-1, 1)\n",
    "    midi_out = np.where(seq == row_maxes, 1, 0)\n",
    "    np.savetxt(\"midi/csv_midi_out_{}.csv\".format(i), midi_out, delimiter=\";\")\n",
    "\n",
    "    midi = builder.midi_from_piano_roll(midi_out)\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(\"Midi {}\".format(i))\n",
    "    \n",
    "    builder.plot_midi(midi)\n",
    "    plt.savefig(\"midi/img_midi_{}.png\".format(i))\n",
    "\n",
    "    midi.write('midi/{}.mid'.format(i))\n",
    "\n",
    "    #synth, rate = builder.play_midi(midi)\n",
    "    #Audio(synth, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.detach().numpy()\n",
    "x_np.shape\n",
    "for i, seq in enumerate(x_np):\n",
    "    midi_out = seq\n",
    "\n",
    "    # Only silence in this one :(\n",
    "    if len(np.unique(midi_out)) == 1:\n",
    "        continue\n",
    "    \n",
    "    midi = builder.midi_from_piano_roll(midi_out)\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(\"Orig Midi {}\".format(i))\n",
    "\n",
    "    builder.plot_midi(midi)\n",
    "    plt.savefig(\"midi/img_midi_{}_orig.png\".format(i))\n",
    "\n",
    "    midi.write('midi/{}_orig.mid'.format(i))\n",
    "\n",
    "    #synth, rate = builder.play_midi(midi)\n",
    "    #Audio(synth, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from latent space\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 32\n",
    "input_size = 512\n",
    "\n",
    "z = torch.randn(sequence_length, batch_size, input_size)\n",
    "print(z.shape)\n",
    "# Define the conductor and note decoder\n",
    "conductor = nn.LSTM(input_size, input_size)\n",
    "decoder = nn.LSTM(2*input_size, input_size)\n",
    "\n",
    "# Linear note to note type (classes)\n",
    "classes = 4\n",
    "linear = nn.Linear(input_size, classes)\n",
    "\n",
    "conductor_hidden = (torch.randn(1, batch_size, input_size), torch.randn(1, batch_size, input_size))\n",
    "notes = []\n",
    "\n",
    "# For the first timestep the note is the embedding\n",
    "note = torch.zeros(batch_size, batch_size, input_size)\n",
    "\n",
    "# Go through each element in the latent sequence\n",
    "for i in range(sequence_length):\n",
    "    \n",
    "    # Generate an embedding vector\n",
    "    embedding, conductor_hidden = conductor(z[i].view(1, 1, -1), conductor_hidden)    \n",
    "\n",
    "    # Reset the decoder state of each 16 bar sequence\n",
    "    decoder_hidden = (torch.randn(1, batch_size, input_size), torch.randn(1, batch_size, input_size))\n",
    "\n",
    "    for _ in range(16):\n",
    "        # Concat embedding with previous note\n",
    "        e = torch.cat([embedding, note], dim=-1)\n",
    "        \n",
    "        # Generate a single note\n",
    "        note, decoder_hidden = decoder(e.view(1, 1, -1), decoder_hidden)\n",
    "        \n",
    "        # The note vector must be a probability of the different note types, e.g. (C#, F, E)\n",
    "        notes.append(torch.softmax(linear(note.view(batch_size, -1)), dim=1))\n",
    "        \n",
    "notes = torch.cat(notes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
